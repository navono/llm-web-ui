name: llm-web-ui

networks:
  llm-network:
    driver: bridge

services:
  nginx:
    image: nginx:alpine
    container_name: llm-web-ui-gateway
    ports:
      - "8080:8080"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro
    networks:
      - llm-network
    depends_on:
      - open-llm-vtuber
      - indextts2
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "wget --quiet --tries=1 --spider http://localhost:8080/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s

  open-llm-vtuber:
    image: open-llm-vtuber:latest
    container_name: llm-web-ui-vtuber
    networks:
      - llm-network
    expose:
      - "12393"
    volumes:
      # Configuration files
      - ./open-llm-vtuber/conf.yaml:/app/conf.yaml:ro
      - ./open-llm-vtuber/mcp_servers.json:/app/mcp_servers.json:ro
      # User data directories
      - ./open-llm-vtuber/avatars:/app/avatars
      - ./open-llm-vtuber/backgrounds:/app/backgrounds
      - ./open-llm-vtuber/characters:/app/characters
      - ./open-llm-vtuber/live2d-models:/app/live2d-models
      # Cache and models
      - ./open-llm-vtuber/cache:/app/cache
      - ./open-llm-vtuber/models:/app/models
      # Logs
      - ./open-llm-vtuber/logs:/app/logs
    environment:
      - HF_HOME=/app/models
      - MODELSCOPE_CACHE=/app/models
      # Uncomment to use Hugging Face mirror
      # - HF_ENDPOINT=https://hf-mirror.com
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:12393/"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s

  indextts2:
    build:
      context: ..
      dockerfile: docker/Dockerfile.indextts2
      args:
        HTTP_PROXY: ${PROXY_SERVER:-}
        HTTPS_PROXY: ${PROXY_SERVER:-}
        NO_PROXY: ${NO_PROXY:-}
    image: indextts2:latest
    container_name: llm-web-ui-indextts2
    networks:
      - llm-network
    expose:
      - "12234"
    volumes:
      # 挂载整个 HuggingFace 模型目录以支持符号链接
      - "/mnt/e/data/hf_models/hub/models--IndexTeam--IndexTTS-2:/app/models_cache"
      # 挂载音频提示文件目录
      - "/mnt/e/OneDrive/data_sync/audio_samples:/app/audio_prompts"
      # 挂载 HuggingFace 缓存（可选）
      - "/mnt/e/data/hf_models:/root/.cache/huggingface"
      # 输出目录（可选）
      - "./output:/app/output"
    environment:
      - PYTHONUNBUFFERED=1
      - CUDA_VISIBLE_DEVICES=0
      - PORT=12234
    restart: unless-stopped
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
